{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e1192c-4b79-4ac2-a867-5df33a97c54a",
   "metadata": {},
   "source": [
    "# Weather Wiz: An AI-Based Weather Forecasting Project\n",
    "\n",
    "Final project for the course Machine Learning in Earth and Environmental Sciences (70938) by Prof. Efrat Morin  \n",
    "Authors:  \n",
    "Noam Shabat – Noam.Shabat@mail.huji.ac.il  \n",
    "Tomer Vagenfeld – Tomer.vagenfeld@mail.huji.ac.il\n",
    "\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "Weather Wiz is an AI-based project to forecast ground temperature using 25 years of multi-station meteorological data provided by the Israel Meteorological Service (IMS). This project explores a range of machine learning approaches—from traditional regularized regression models to deep learning architectures such as Long Short-Term Memory networks (LSTM) and Graph Neural Networks (GNN). By capturing both temporal trends and spatial correlations, the system produces short-term forecasts.\n",
    "\n",
    "In this paper, we describe the problem formulation, data characteristics, preprocessing and exploratory analyses, modeling methodologies, and experimental results, and discuss insights obtained in the project.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Accurate weather forecasting is important in many fields, including agriculture, energy, transportation, and emergency management. The Weather Wiz project focuses on predicting ground temperature (TG) using a dataset spanning 25 years of high-resolution weather measurements. Given the complex nature of meteorological phenomena—which are influenced by humidity, wind patterns, and precipitation—this project employs a combination of linear models, ensemble methods, and deep learning techniques. In particular, the use of Graph Neural Networks enables the integration of spatial relationships among weather stations, thereby improving prediction performance.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Description\n",
    "\n",
    "### 2.1 Data Source, Station Map, and Nature\n",
    "The dataset is obtained from the [Israel Meteorological Service (IMS)](https://ims.gov.il), which records weather data from multiple stations across Israel. Observations are recorded every 10 minutes and subsequently aggregated into hourly or daily summaries. This extensive temporal coverage and multi-station design provide a detailed view of regional weather dynamics.\n",
    "\n",
    "**Station Map:**  \n",
    "The station locations were extracted directly from the IMS API, and the map was created using ArcGIS.  \n",
    "![Station Map](images/station_map.png)  \n",
    "*Figure 2.1 – Station Map: This map displays the geographic locations of the IMS stations across Israel.*\n",
    "\n",
    "### 2.2 Data Extraction from the IMS API\n",
    "Data extraction was performed by interfacing with the IMS API, which provides secure access to detailed meteorological data in JSON format. By specifying station identifiers and a defined date range, the system automatically queries and aggregates data on a monthly basis to address API limitations. The extracted data is then converted into structured tabular formats for further processing and analysis, ensuring complete coverage of the 25-year period.\n",
    "\n",
    "### 2.3 Features and Target Variable\n",
    "- **Features:**\n",
    "  - **Meteorological Variables:** Measurements such as relative humidity (RH), wind speed (WS), wind direction (WD), and rainfall (Rain).\n",
    "  - **Engineered Features:**  \n",
    "    - *Temporal Attributes:* Hour of day along with sine and cosine transformations to capture cyclical patterns.  \n",
    "    - *Wind Vectors:* Components derived from wind speed and wind direction that quantify directional wind influence.\n",
    "- **Target:**  \n",
    "  - **Ground Temperature (TG):** The variable to be predicted, representing the ground-level temperature.\n",
    "\n",
    "### 2.4 Data Visualization\n",
    "- **Feature Explanation:**  \n",
    "  An illustration of the features and their descriptions is provided below.  \n",
    "  ![Features explaination](images/features_explain.png)  \n",
    "  *Figure 2.2 – Features Explanation: This diagram details the various meteorological. Image provided by the IMS.*\n",
    "\n",
    "- **Ground Temperature Analysis:**  \n",
    "  The distribution and time series of ground temperature (TG) are visualized as follows:  \n",
    "  ![TG Distribution](images/TG_distribution.png)  \n",
    "  *Figure 2.3 – TG Distribution: This histogram shows the distribution of ground temperature values across the dataset.*  \n",
    "\n",
    "  ![TG Series Full](images/TG_series%20full.png)  \n",
    "  *Figure 2.4 – TG Series (Full): This plot shows the complete time series of ground temperature measurements over the 25-year period.*  \n",
    "\n",
    "  ![TG Series](images/TG_series.png)  \n",
    "  *Figure 2.5 – TG Series: This plot provides a detailed view of short-term fluctuations in ground temperature.*\n",
    "\n",
    "### 2.5 Sample Data\n",
    "Below is a table presenting sample data extracted from the IMS API, including the major features used later in training. *Reminder that the data captured by the meteorological station is taken in 10-minute intervals.*\n",
    "\n",
    "| Region ID | Station Name           | station_id | datetime                       | RH | Rain | TG   | WD  | WS  | Latitude | Longitude | Min Date                       | Max Date                       | Date Range (days approx.) |\n",
    "|-----------|------------------------|------------|--------------------------------|----|------|------|-----|-----|----------|-----------|--------------------------------|--------------------------------|---------------------------|\n",
    "| 8         | TAVOR KADOORIE        | 13         | 2010-11-30T04:00:00+02:00      | 25 | 0    | 9.1  | 306 | 1.8 | 32.7053  | 35.4069   | 2000-01-31T00:00:00+02:00      | 2024-09-30T23:50:00+03:00      | 9000                      |\n",
    "| 9         | ZEMAH                 | 8          | 2022-03-31T19:50:00+03:00      | 77 | 0    | 13.8 | 201 | 0.1 | 32.7024  | 35.5839   | 2000-01-31T00:00:00+02:00      | 2024-10-31T23:50:00+02:00      | 9000                      |\n",
    "| 8         | TAVOR KADOORIE        | 13         | 2017-07-31T13:20:00+03:00      | 38 | 0    | 52.8 | 302 | 2.9 | 32.7053  | 35.4069   | 2000-01-31T00:00:00+02:00      | 2024-09-30T23:50:00+03:00      | 9000                      |\n",
    "| 9         | GILGAL                | 30         | 2018-06-30T21:10:00+03:00      | 45 | 0    | 27.9 | 254 | 0.8 | 31.9973  | 35.4509   | 2000-01-31T00:00:00+02:00      | 2024-12-31T23:50:00+02:00      | 9000                      |\n",
    "| 9         | GILGAL                | 30         | 2022-04-30T09:20:00+03:00      | 27 | 0    | 40.4 | 121 | 0.8 | 31.9973  | 35.4509   | 2000-01-31T00:00:00+02:00      | 2024-12-31T23:50:00+02:00      | 9000                      |\n",
    "| 9         | GILGAL                | 30         | 2001-07-31T12:10:00+03:00      | 39 | 0    | 51.3 | 147 | 1.8 | 31.9973  | 35.4509   | 2000-01-31T00:00:00+02:00      | 2024-12-31T23:50:00+02:00      | 9000                      |\n",
    "| 8         | MEROM GOLAN PICMAN    | 10         | 2013-04-30T18:30:00+03:00      | 38 | 0    | 18.3 | 306 | 2.5 | 33.1288  | 35.8045   | 2000-01-31T00:00:00+02:00      | 2024-12-31T23:50:00+02:00      | 9000                      |\n",
    "| 8         | TAVOR KADOORIE        | 13         | 2011-12-31T06:20:00+02:00      | 87 | 0    | 6.3  | 320 | 1.1 | 32.7053  | 35.4069   | 2000-01-31T00:00:00+02:00      | 2024-09-30T23:50:00+03:00      | 9000                      |\n",
    "| 10        | YOTVATA               | 36         | 2012-05-31T09:40:00+03:00      | 31 | 0    | 38.8 | 6   | 2.9 | 29.8851  | 35.0771   | 2000-02-29T00:00:00+02:00      | 2024-12-31T23:50:00+02:00      | 9000                      |\n",
    "| 9         | GILGAL                | 30         | 2011-02-28T05:00:00+02:00      | 80 | 0    | 8.2  | 232 | 1.6 | 31.9973  | 35.4509   | 2000-01-31T00:00:00+02:00      | 2024-12-31T23:50:00+02:00      | 9000                      |\n",
    "\n",
    "*Table 2.1 – Sample Data: This table presents 10 rows from the dataset extracted via the IMS API, including station identifiers, timestamps, and key meteorological measurements, along with additional metadata (e.g., latitude, longitude, date range).*\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Data Preprocessing and Exploratory Data Analysis\n",
    "\n",
    "### 3.1 Data Cleaning and Preparation\n",
    "Ensuring high data quality is essential for reliable model training. Our data cleaning process included:\n",
    "- **Removal of Unrealistic Values:**  \n",
    "  Data entries were filtered to enforce physical plausibility (e.g., \\(0 \\leq \\text{RH} \\leq 100\\) and \\(-15 \\leq \\text{TG} \\leq 50\\)). Outliers and values outside known meteorological ranges were removed.\n",
    "- **Handling Missing Values:**  \n",
    "  Missing or null values in critical variables were identified and addressed. Depending on the variable, rows with missing data were either dropped or imputed.\n",
    "- **Datetime Conversion and Sorting:**  \n",
    "  Timestamp strings were converted into datetime objects to ensure proper chronological ordering, which is critical for time series analysis.\n",
    "- **Normalization and Scaling:**  \n",
    "  To ensure that all input features contribute equally during model training, the data was scaled using a MinMaxScaler. The scaling transformation is defined as:\n",
    "  $$\n",
    "  x' = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}},\n",
    "  $$\n",
    "  where \\(x\\) is the original feature value, and \\(x_{\\min}\\) and \\(x_{\\max}\\) are the minimum and maximum values of that feature. This process is crucial for models sensitive to input scale, as it improves convergence speed and stability.\n",
    "- **Feature Engineering:**  \n",
    "  Additional features were computed to capture underlying patterns in the data.\n",
    "\n",
    "#### Mathematical Operations in Feature Engineering\n",
    "To represent cyclical and directional information effectively, the following mathematical transformations were applied:\n",
    "- **Cyclical Time Features:**  \n",
    "  The hour of the day was transformed using sine and cosine functions:\n",
    "  $$\n",
    "  \\text{hour}_{\\sin} = \\sin\\left(\\frac{2\\pi \\times \\text{hour}}{24}\\right),\n",
    "  $$\n",
    "  $$\n",
    "  \\text{hour}_{\\cos} = \\cos\\left(\\frac{2\\pi \\times \\text{hour}}{24}\\right).\n",
    "  $$\n",
    "  These transformations allow the model to capture the periodic nature of time.\n",
    "  \n",
    "- **Wind Vector Components:**  \n",
    "  Wind speed (\\(WS\\)) and wind direction (\\(WD\\)) were converted from polar to Cartesian coordinates:\n",
    "  $$\n",
    "  wind_x = WS \\times \\cos\\left(\\frac{\\pi \\times WD}{180}\\right),\n",
    "  $$\n",
    "  $$\n",
    "  wind_y = WS \\times \\sin\\left(\\frac{\\pi \\times WD}{180}\\right).\n",
    "  $$\n",
    "  This conversion provides a richer representation of wind dynamics.\n",
    "\n",
    "### 3.2 Exploratory Data Analysis (EDA)\n",
    "EDA was conducted to understand the structure and variability of the dataset:\n",
    "- **Distribution Analysis:**  \n",
    "  Histograms and density plots illustrate the distributions of temperature, humidity, and rainfall.\n",
    "- **Time Series Visualization:**  \n",
    "  Time series plots highlight both short-term fluctuations and long-term trends in ground temperature.\n",
    "- **Correlation Analysis:**  \n",
    "  Correlation matrices help identify significant relationships among features, guiding further feature engineering.\n",
    "- **Missing Value Patterns:**  \n",
    "  Visualizations of missing data assess data quality and inform imputation strategies.\n",
    "\n",
    "Additional visualizations, such as zoomed-in seasonal trends and scatter plots comparing multiple variables, provided further insights that informed model development.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Methodology\n",
    "\n",
    "### 4.1 Modeling Approaches and Rationale\n",
    "A multi-model strategy was implemented to address different aspects of the data:\n",
    "- **Lasso Regression:**  \n",
    "  Used as a baseline model for its simplicity and interpretability. Its L1 regularization promotes sparsity, thereby highlighting the most relevant features.\n",
    "- **Random Forest:**  \n",
    "  An ensemble method that captures complex nonlinear interactions among features. Its robustness makes it well-suited for high-dimensional data.\n",
    "- **Long Short-Term Memory (LSTM) Networks:**  \n",
    "  LSTMs are effective at capturing long-term dependencies in sequential data, making them ideal for modeling temporal dynamics.\n",
    "- **Graph Neural Networks (GNN):**  \n",
    "  GNNs integrate spatial information by treating weather stations as nodes in a graph, leveraging both spatial and temporal correlations to capture localized weather patterns.\n",
    "\n",
    "### 4.2 Explanation of Graph Neural Networks (GNN)\n",
    "Graph Neural Networks (GNNs) are neural architectures designed to operate on graph-structured data. Unlike traditional neural networks that work on fixed grids or sequences, GNNs handle irregular, interconnected data. In a GNN, each node (e.g., a weather station) gathers information from its neighboring nodes through a process called message passing. During this process, each node updates its representation by combining its features with those of its neighbors via learnable functions. This approach enables the network to capture both local interactions and the overall structure of the graph, making it particularly effective for modeling spatial relationships.\n",
    "\n",
    "**Unique Edge Technique Attempt:**  \n",
    "We initially attempted a “unique edge” technique to incorporate additional station-to-station relationships or domain-specific spatial distances. However, we found that leveraging this approach exceeded our available RAM resources, making it impractical for our current hardware setup. We expect that a properly optimized unique edge strategy would further enhance the GNN’s capacity to capture spatial dependencies, as it would provide more granular connectivity between stations.\n",
    "\n",
    "### 4.3 Training and Optimization\n",
    "\n",
    "#### 4.3.1 Optimization Functions in the Models\n",
    "Each model uses an optimization strategy tailored to its structure:\n",
    "- **LSTM Models – Adam Optimizer:**  \n",
    "  The LSTM networks are trained using the Adam algorithm, which adapts the learning rate for each parameter based on estimates of the first and second moments of the gradients:\n",
    "  $$\n",
    "  m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t,\n",
    "  $$\n",
    "  $$\n",
    "  v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2,\n",
    "  $$\n",
    "  $$\n",
    "  \\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1-\\beta_2^t},\n",
    "  $$\n",
    "  $$\n",
    "  w_{t+1} = w_t - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon},\n",
    "  $$\n",
    "  where \\(g_t\\) is the gradient at time \\(t\\) and \\(\\alpha\\), \\(\\beta_1\\), \\(\\beta_2\\), and \\(\\epsilon\\) are hyperparameters.\n",
    "  \n",
    "- **GNN Models – AdamW Optimizer:**  \n",
    "  The GNN models use the AdamW optimizer, which decouples weight decay from the gradient update to improve generalization:\n",
    "  $$\n",
    "  w_{t+1} = w_t - \\alpha \\left( \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} + \\lambda w_t \\right),\n",
    "  $$\n",
    "  where \\(\\lambda\\) is the weight decay coefficient.\n",
    "  \n",
    "- **Lasso Regression and Random Forest:**  \n",
    "  Lasso Regression uses coordinate descent to solve:\n",
    "  $$\n",
    "  \\min_{w} \\; \\|y - Xw\\|_2^2 + \\alpha \\|w\\|_1,\n",
    "  $$\n",
    "  promoting sparsity in \\(w\\). Random Forests build an ensemble of decision trees using recursive partitioning and impurity minimization (e.g., minimizing mean squared error) to generate predictions.\n",
    "\n",
    "#### 4.3.2 Hyperparameter Tuning\n",
    "Hyperparameters such as the number of hidden units, dropout rates, learning rates, and the number of epochs were tuned within predefined ranges (e.g., LSTM hidden units between 32 and 128, GNN dimensions between 32 and 256) to ensure efficient convergence and robust performance.\n",
    "\n",
    "### 4.4 Cross-Validation and Data Folds\n",
    "To evaluate model performance reliably, a custom time series cross-validation strategy was employed:\n",
    "- **Chronological Splitting:**  \n",
    "  The dataset is divided into sequential folds, where each fold consists of a training set (earlier time periods) and a test set (later time periods), reflecting a realistic forecasting scenario.\n",
    "- **Multiple Folds:**  \n",
    "  Evaluating across several folds provides insights into the stability and consistency of the model’s predictions over different time intervals.\n",
    "- **Avoiding Data Leakage:**  \n",
    "  Preserving the temporal order prevents future information from influencing the training process, ensuring an unbiased evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Experimental Results\n",
    "\n",
    "### 5.1 Evaluation Metrics\n",
    "Models were assessed using the following metrics:\n",
    "- **Mean Absolute Error (MAE):** The average absolute difference between predicted and actual temperatures.\n",
    "- **Mean Squared Error (MSE):** The average squared difference between predicted and actual temperatures.\n",
    "- **Coefficient of Determination (R² Score):** The proportion of variance in the target variable explained by the model.\n",
    "- **Median Absolute Percentage Error (MdAPE):** A relative measure of prediction accuracy.\n",
    "\n",
    "### 5.2 Visualizations of Model Performance\n",
    "Several plots were generated to illustrate model performance:\n",
    "- **Random Forest Results:**  \n",
    "  ![Random Forest](images/random_forest.png)  \n",
    "  *Figure 5.1 – Random Forest Results: This figure illustrates the performance of the Random Forest model in predicting ground temperature.*\n",
    "- **Lasso Regression Results:**  \n",
    "  ![Lasso](images/lasso.png)  \n",
    "  *Figure 5.2 – Lasso Regression Results: This figure shows the performance of the Lasso Regression model as a baseline.*\n",
    "- **LSTM Performance:**  \n",
    "  ![LSTM](images/lstm.png)  \n",
    "  *Figure 5.3 – LSTM Performance: This figure depicts the LSTM model's ability to capture temporal dependencies in the data.*\n",
    "- **Ground Temperature Predictions:**  \n",
    "  ![TG Predictions](images/TG_pred.png)  \n",
    "  *Figure 5.4 – Ground Temperature Predictions: This plot compares the actual and forecasted ground temperature values over time.*  \n",
    "  ![TG Predictions 2](images/TG_pred_2.png)  \n",
    "  *Figure 5.5 – Ground Temperature Predictions (Alternate View): This plot provides an alternative visualization of the forecasted ground temperature.*\n",
    "- **Loss Curve for GNN:**  \n",
    "  ![Loss Curve](images/loss.png)  \n",
    "  *Figure 5.6 – Loss Curve for GNN: This graph shows the training and validation loss trends during GNN model training.*\n",
    "- **Evaluation Metrics:**  \n",
    "  ![MAE](images/mae.png)  \n",
    "  *Figure 5.7 – MAE: This figure displays the Mean Absolute Error for the models across the test folds.*  \n",
    "  ![MSE](images/mse.png)  \n",
    "  *Figure 5.8 – MSE: This figure shows the Mean Squared Error for the models.*  \n",
    "  ![R²](images/r2.png)  \n",
    "  *Figure 5.9 – R² Score: This figure illustrates the R² scores, indicating the proportion of variance explained by the models.*\n",
    "- **Cross-Validation Summary:**  \n",
    "  ![Cross-Validation Summary](images/cross.png)  \n",
    "  *Figure 5.10 – Cross-Validation Summary: This bar chart summarizes the performance of different models across multiple cross-validation folds.*\n",
    "\n",
    "### 5.3 Discussion of Results\n",
    "Results indicate that:\n",
    "- **Lasso Regression** provides a strong, interpretable baseline.\n",
    "- **Random Forest** effectively captures nonlinear interactions, though its predictions may exhibit higher variance.\n",
    "- **LSTM Networks** excel in modeling temporal dependencies, particularly for short-term forecasts.\n",
    "- **GNN Models** enhance prediction accuracy by incorporating spatial correlations, especially in regions with a dense network of weather stations.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Discussion\n",
    "\n",
    "The multi-model approach of Weather Wiz highlights the importance of integrating various techniques when working with complex weather data. Traditional methods, while valuable for their interpretability, are complemented by deep learning approaches that more effectively capture temporal and spatial patterns. Our custom time series cross-validation strategy further ensures that the models are rigorously evaluated on unseen data. Although further refinements in feature engineering and hyperparameter tuning may improve performance, the current results support the overall approach for academic research in weather forecasting.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Conclusion\n",
    "\n",
    "Weather Wiz provides a comprehensive approach to forecasting ground temperature by combining traditional and advanced machine learning methods. By leveraging both temporal and spatial features, the project achieves a high level of predictive accuracy. Future work will involve extending the framework to additional weather parameters, refining spatial modeling techniques, and exploring longer forecasting horizons.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Future Work and Recommendations\n",
    "\n",
    "- **Incorporation of Additional Metrics:** Explore predictions for other weather phenomena such as radiation, precipitation, and wind speed.  \n",
    "- **Enhanced Spatial Modeling:** Investigate further refinements to the GNN architecture, including dynamic edge weights based on real-time data.  \n",
    "- **Extended Forecast Horizons:** Experiment with longer sequence lengths and alternative temporal models to support medium- and long-term forecasts.  \n",
    "- **Integration of External Data:** Consider incorporating satellite or remote sensing data to enhance the feature set and overall model robustness.\n",
    "\n",
    "---\n",
    "\n",
    "## Acknowledgments\n",
    "This research was made possible by the data provided by the [Israel Meteorological Service (IMS)](https://ims.gov.il). We acknowledge the contributions of researchers and practitioners in machine learning and meteorology whose work has informed this project.\n",
    "\n",
    "---\n",
    "\n",
    "*Note: This paper emphasizes the scientific and methodological aspects of the project. For detailed technical implementation, code, and installation instructions, please refer to the supplementary documentation available in the project repository.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
